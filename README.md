Cerberus
==================


[![codecov](https://codecov.io/gh/richardnixonafj/cerberus/branch/master/graph/badge.svg)](https://codecov.io/gh/richardnixonafj/cerberus)


Meu primeiro projeto de um crawler em python
---------------------------------------------



Neste tutorial, você construiu um spider totalmente funcional que extrai dados de páginas web em menos de trinta linhas de código. É um ótimo começo, mas há muitas coisas divertidas que você pode fazer com esse spider. Aqui estão algumas maneiras de expandir o código que você escreveu. Eles vão te dar alguns dados para a prática do scrap.

 

Desafios
---------
- [ ] No momento, estamos analisando apenas os resultados de 2016, como você deve ter percebido da parte 2016 de http://brickset.com/sets/year-2016 - Como você faria o crawling dos resultados de outros anos?

- [ ] Há um preço de varejo incluído na maioria dos conjuntos. Como você extrai os dados dessa célula? Como você obteria um número bruto disso? Dica: você encontrará os dados em um dt assim como o número de peças e minifigs.

- [ ] A maioria dos resultados possui tags que especificam dados semânticos sobre os conjuntos ou o seu contexto. Como fazer crawling neles, já que existem várias tags para um único conjunto?

[Referencia](https://www.digitalocean.com/community/tutorials/como-fazer-crawling-em-uma-pagina-web-com-scrapy-e-python-3-pt)

